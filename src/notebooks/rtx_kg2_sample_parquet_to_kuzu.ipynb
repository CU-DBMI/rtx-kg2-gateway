{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94db8d0f-2dba-41af-a860-fcbe60c1824b",
   "metadata": {},
   "source": [
    "# Generate RTX-KG2 Sample Parquet to Kuzu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e598413e-509b-48b9-aab3-1c703b364c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import pathlib\n",
    "import shutil\n",
    "from typing import Any, Dict, Generator, List, Literal\n",
    "\n",
    "import awkward as ak\n",
    "import ijson\n",
    "import kuzu\n",
    "import pyarrow as pa\n",
    "import requests\n",
    "from genson import SchemaBuilder\n",
    "from pyarrow import parquet\n",
    "from rtx_kg2_functions import (\n",
    "    count_items_under_top_level_name,\n",
    "    find_top_level_names,\n",
    "    parse_items_by_topmost_item_name,\n",
    "    parse_metadata_by_object_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46ab8fed-b335-4d55-a73e-a6904bc0bc46",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kuzu dir: data/kg2c_lite_2.8.4.sample.dataset.kuzu\n"
     ]
    }
   ],
   "source": [
    "# set data to be used throughout notebook\n",
    "chunk_size = 1\n",
    "data_dir = \"data\"\n",
    "parquet_dir = f\"{data_dir}/\"\n",
    "source_data_url = \"https://github.com/ncats/translator-lfs-artifacts/raw/main/files/kg2c_lite_2.8.4.json.gz\"\n",
    "target_extracted_sample_data = f\"{data_dir}/{pathlib.Path(source_data_url).name.replace('.json.gz', '.sample.json')}\"\n",
    "parquet_dir = target_extracted_sample_data.replace(\".json\", \".dataset.parquet\")\n",
    "kuzu_dir = target_extracted_sample_data.replace(\".json\", \".dataset.kuzu\")\n",
    "target_extracted_sample_data_schema_file = target_extracted_sample_data.replace(\n",
    "    \".json\", \".schema.json\"\n",
    ")\n",
    "print(f\"Kuzu dir: {kuzu_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dc7f93e-e2ea-4840-868b-885afaff38f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create path for the kuzu database to reside\n",
    "shutil.rmtree(kuzu_dir)\n",
    "pathlib.Path(kuzu_dir).mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b65ae82e-cdb2-4c10-a5a5-4114c327a06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init a Kuzu database and connection\n",
    "db = kuzu.Database(f\"{kuzu_dir}\")\n",
    "kz_conn = kuzu.Connection(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "211ad500-7684-43cc-b124-97d1f6063a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cypher_table_create_stmt_from_parquet_file(\n",
    "    parquet_file: str,\n",
    "    table_type: Literal[\"node\", \"rel\"],\n",
    "    table_name: str,\n",
    "    table_pkey_parquet_field_name: str = \"id\",\n",
    "    rel_table_field_mapping: Dict[str, str] = {\"from\": \"nodes\", \"to\": \"nodes\"},\n",
    "    # specify a map for from to specification\n",
    "    # to move these to first two cols of related table\n",
    "    edges_to_or_from_fieldnames: List[str] = [\"subject\", \"object\"],\n",
    "):\n",
    "\n",
    "    parquet_schema = parquet.read_schema(parquet_file)\n",
    "\n",
    "    if table_pkey_parquet_field_name not in [field.name for field in parquet_schema]:\n",
    "        raise LookupError(\n",
    "            f\"Unable to find field {table_pkey_parquet_field_name} in parquet file {parquet_file}.\"\n",
    "        )\n",
    "\n",
    "    # Map Parquet data types to Cypher data types\n",
    "    # more details here: https://kuzudb.com/docusaurus/cypher/data-types/\n",
    "    parquet_to_cypher_type_mapping = {\n",
    "        \"string\": \"STRING\",\n",
    "        \"int32\": \"INT32\",\n",
    "        \"int64\": \"INT64\",\n",
    "        \"number\": \"FLOAT\",\n",
    "        \"float\": \"FLOAT\",\n",
    "        \"double\": \"FLOAT\",\n",
    "        \"boolean\": \"BOOLEAN\",\n",
    "        \"object\": \"MAP\",\n",
    "        \"array\": \"INT64[]\",\n",
    "        \"list<element: string>\": \"STRING[]\",\n",
    "        \"null\": \"NULL\",\n",
    "        \"date\": \"DATE\",\n",
    "        \"time\": \"TIME\",\n",
    "        \"datetime\": \"DATETIME\",\n",
    "        \"timestamp\": \"DATETIME\",\n",
    "        \"any\": \"ANY\",\n",
    "    }\n",
    "\n",
    "    # Generate Cypher field type statements\n",
    "    cypher_fields_from_parquet_schema = \", \".join(\n",
    "        [\n",
    "            # note: we use string splitting here for nested types\n",
    "            # for ex. list<element: string>\n",
    "            f\"{field.name} {parquet_to_cypher_type_mapping.get(str(field.type))}\"\n",
    "            for idx, field in enumerate(parquet_schema)\n",
    "            if table_type == \"node\" or (table_type == \"rel\" and idx > 1)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # branch for creating node table\n",
    "    if table_type == \"node\":\n",
    "        return (\n",
    "            f\"CREATE NODE TABLE {table_name}\"\n",
    "            f\"({cypher_fields_from_parquet_schema}, \"\n",
    "            f\"PRIMARY KEY ({table_pkey_parquet_field_name}))\"\n",
    "        )\n",
    "\n",
    "    # else we return for rel tables\n",
    "    return (\n",
    "        f\"CREATE REL TABLE {table_name}\"\n",
    "        f\"(FROM {rel_table_field_mapping['from']} TO {rel_table_field_mapping['to']}, \"\n",
    "        f\"{cypher_fields_from_parquet_schema})\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51c8daaf-e7b6-41dc-84bf-c2cf1d615eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_table_if_exists(kz_conn: kuzu.connection.Connection, table_name: str):\n",
    "    try:\n",
    "        kz_conn.execute(f\"DROP TABLE {table_name}\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Warning: no need to drop table.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6f88caf-239a-4be7-86ff-919d39ca10fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the following create statement to create table:\n",
      "\n",
      "CREATE NODE TABLE nodes(id STRING, name STRING, all_categories STRING[], category STRING, PRIMARY KEY (id))\n",
      "\n",
      "\n",
      "Using the following create statement to create table:\n",
      "\n",
      "CREATE REL TABLE edges(FROM nodes TO nodes, qualified_object_aspect STRING, predicate STRING, domain_range_exclusion STRING, qualified_object_direction STRING, id INT64, primary_knowledge_source STRING, qualified_predicate STRING)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_name_to_cypher_table_type_map = {\"nodes\": \"node\", \"edges\": \"rel\"}\n",
    "\n",
    "drop_table_if_exists(kz_conn=kz_conn, table_name=\"edges\")\n",
    "drop_table_if_exists(kz_conn=kz_conn, table_name=\"nodes\")\n",
    "\n",
    "# note: we provide specific ordering here to ensure nodes are created before edges\n",
    "for path in [f\"{parquet_dir}/nodes\", f\"{parquet_dir}/edges\"]:\n",
    "\n",
    "    # use first file discovered as basis for schema\n",
    "    first_pq_file = next(pathlib.Path(path).glob(\"*.parquet\"))\n",
    "\n",
    "    create_stmt = generate_cypher_table_create_stmt_from_parquet_file(\n",
    "        parquet_file=first_pq_file,\n",
    "        table_type=dataset_name_to_cypher_table_type_map[first_pq_file.parent.name],\n",
    "        table_name=first_pq_file.parent.name,\n",
    "        table_pkey_parquet_field_name=\"id\",\n",
    "    )\n",
    "\n",
    "    print(f\"Using the following create statement to create table:\\n\\n{create_stmt}\\n\\n\")\n",
    "    kz_conn.execute(create_stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a75ef8d-b58c-4937-a46e-fe22eb52af16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: we provide specific ordering here to ensure nodes are created before edges\n",
    "for path in [f\"{parquet_dir}/nodes\", f\"{parquet_dir}/edges\"]:\n",
    "\n",
    "    print(f\"Working on kuzu ingest of parquet dataset: {path} \")\n",
    "    # uses wildcard functionality for all files under parquet dataset dir\n",
    "    # see: https://kuzudb.com/docusaurus/data-import/csv-import#copy-from-multiple-csv-files-to-a-single-table\n",
    "    kz_conn.execute(f'COPY {pathlib.Path(path).name} FROM \"{path}/*.parquet\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
