{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94db8d0f-2dba-41af-a860-fcbe60c1824b",
   "metadata": {},
   "source": [
    "# RTX-KG2 Functions\n",
    "\n",
    "Convenience notebook for using functions from a single location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e598413e-509b-48b9-aab3-1c703b364c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import pathlib\n",
    "import shutil\n",
    "from typing import Any, Dict, Generator, List, Literal\n",
    "\n",
    "import ijson\n",
    "import kuzu\n",
    "import requests\n",
    "from genson import SchemaBuilder\n",
    "from pyarrow import parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31cc54d9-df5c-410d-97ea-603e493e42e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, download_dir):\n",
    "    # referenced with modification from:\n",
    "    # https://stackoverflow.com/a/16696317\n",
    "    local_filename = url.split(\"/\")[-1]\n",
    "    # NOTE the stream=True parameter below\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(f\"{download_dir}/{local_filename}\", \"wb\") as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192):\n",
    "                # If you have chunk encoded response uncomment if\n",
    "                # and set chunk_size parameter to None.\n",
    "                # if chunk:\n",
    "                f.write(chunk)\n",
    "    return local_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68b4285f-241c-4317-baa0-b0c4949710a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_level_names(json_file: str) -> Generator[str, None, None]:\n",
    "    \"\"\"\n",
    "    Find the topmost item names by way of streaming a json\n",
    "    file through ijson.\n",
    "    \"\"\"\n",
    "    with open(json_file, \"r\") as f:\n",
    "        parser = ijson.parse(f)\n",
    "        depth = 0\n",
    "        for prefix, event, value in parser:\n",
    "            if event == \"start_map\":\n",
    "                depth += 1\n",
    "            elif event == \"end_map\":\n",
    "                depth -= 1\n",
    "            elif event == \"map_key\" and depth == 1:\n",
    "                yield value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e0b1528-229e-437b-8405-98c0afcab3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_items_under_top_level_name(json_file: str, top_level_name: str):\n",
    "    \"\"\"\n",
    "    Count items under a top level object name\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    with open(json_file, \"rb\") as f:\n",
    "        parser = ijson.items(f, f\"{top_level_name}.item\")\n",
    "        for item in parser:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1ded656-e618-4956-9eeb-4ec6651c22a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_items_by_topmost_item_name(\n",
    "    json_file: str, topmost_item_name: str, chunk_size: int, limit: int = 0\n",
    ") -> Generator[List[Dict[str, Any]], None, None]:\n",
    "    \"\"\"\n",
    "    Parse items using a topmost object name.\n",
    "    \"\"\"\n",
    "    with open(json_file, \"r\") as f:\n",
    "        objects = ijson.items(f, f\"{topmost_item_name}.item\")\n",
    "        chunk = []\n",
    "        limit_count = 0\n",
    "        for item in objects:\n",
    "            if limit == 0 or limit_count < limit:\n",
    "                chunk.append(item)\n",
    "                if len(chunk) == chunk_size:\n",
    "                    yield chunk\n",
    "                    limit_count += 1\n",
    "                    chunk = []\n",
    "        # Yield the last chunk if there are remaining elements\n",
    "        if chunk:\n",
    "            yield chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "895f978c-dd54-4eeb-b082-f8d50db3eac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_metadata_by_object_name(\n",
    "    json_file: str, metadata_object_name: str\n",
    ") -> Generator[Any, None, None]:\n",
    "    \"\"\"\n",
    "    Extract single value metadata from json file\n",
    "    \"\"\"\n",
    "\n",
    "    with open(json_file, \"r\") as f:\n",
    "        return next(ijson.items(f, metadata_object_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b2b3a8-e6d9-4eb9-a7e7-2249b4bb6183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cypher_table_create_stmt_from_parquet_file(\n",
    "    parquet_file: str,\n",
    "    table_type: Literal[\"node\", \"rel\"],\n",
    "    table_name: str,\n",
    "    table_pkey_parquet_field_name: str = \"id\",\n",
    "    rel_table_field_mapping: Dict[str, str] = {\"from\": \"nodes\", \"to\": \"nodes\"},\n",
    "    # specify a map for from to specification\n",
    "    # to move these to first two cols of related table\n",
    "    edges_to_or_from_fieldnames: List[str] = [\"subject\", \"object\"],\n",
    "):\n",
    "\n",
    "    parquet_schema = parquet.read_schema(parquet_file)\n",
    "\n",
    "    if table_pkey_parquet_field_name not in [field.name for field in parquet_schema]:\n",
    "        raise LookupError(\n",
    "            f\"Unable to find field {table_pkey_parquet_field_name} in parquet file {parquet_file}.\"\n",
    "        )\n",
    "\n",
    "    # Map Parquet data types to Cypher data types\n",
    "    # more details here: https://kuzudb.com/docusaurus/cypher/data-types/\n",
    "    parquet_to_cypher_type_mapping = {\n",
    "        \"string\": \"STRING\",\n",
    "        \"int32\": \"INT32\",\n",
    "        \"int64\": \"INT64\",\n",
    "        \"number\": \"FLOAT\",\n",
    "        \"float\": \"FLOAT\",\n",
    "        \"double\": \"FLOAT\",\n",
    "        \"boolean\": \"BOOLEAN\",\n",
    "        \"object\": \"MAP\",\n",
    "        \"array\": \"INT64[]\",\n",
    "        \"list<element: string>\": \"STRING[]\",\n",
    "        \"null\": \"NULL\",\n",
    "        \"date\": \"DATE\",\n",
    "        \"time\": \"TIME\",\n",
    "        \"datetime\": \"DATETIME\",\n",
    "        \"timestamp\": \"DATETIME\",\n",
    "        \"any\": \"ANY\",\n",
    "    }\n",
    "\n",
    "    # Generate Cypher field type statements\n",
    "    cypher_fields_from_parquet_schema = \", \".join(\n",
    "        [\n",
    "            # note: we use string splitting here for nested types\n",
    "            # for ex. list<element: string>\n",
    "            f\"{field.name} {parquet_to_cypher_type_mapping.get(str(field.type))}\"\n",
    "            for idx, field in enumerate(parquet_schema)\n",
    "            if table_type == \"node\" or (table_type == \"rel\" and idx > 1)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # branch for creating node table\n",
    "    if table_type == \"node\":\n",
    "        return (\n",
    "            f\"CREATE NODE TABLE {table_name}\"\n",
    "            f\"({cypher_fields_from_parquet_schema}, \"\n",
    "            f\"PRIMARY KEY ({table_pkey_parquet_field_name}))\"\n",
    "        )\n",
    "\n",
    "    # else we return for rel tables\n",
    "    return (\n",
    "        f\"CREATE REL TABLE {table_name}\"\n",
    "        f\"(FROM {rel_table_field_mapping['from']} TO {rel_table_field_mapping['to']}, \"\n",
    "        f\"{cypher_fields_from_parquet_schema})\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53059d44-e983-423d-9915-642c2e2f3325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_table_if_exists(kz_conn: kuzu.connection.Connection, table_name: str):\n",
    "    try:\n",
    "        kz_conn.execute(f\"DROP TABLE {table_name}\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Warning: no need to drop table.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
