{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94db8d0f-2dba-41af-a860-fcbe60c1824b",
   "metadata": {},
   "source": [
    "# Generate RTX-KG2 Metanames Parquet to Kuzu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e598413e-509b-48b9-aab3-1c703b364c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import pathlib\n",
    "import shutil\n",
    "from functools import partial\n",
    "from typing import Any, Dict, Generator, List, Literal\n",
    "\n",
    "import awkward as ak\n",
    "import duckdb\n",
    "import ijson\n",
    "import kuzu\n",
    "import pyarrow as pa\n",
    "import requests\n",
    "from genson import SchemaBuilder\n",
    "from pyarrow import parquet\n",
    "from rtx_kg2_functions import (\n",
    "    count_items_under_top_level_name,\n",
    "    drop_table_if_exists,\n",
    "    find_top_level_names,\n",
    "    generate_cypher_table_create_stmt_from_parquet_file,\n",
    "    parse_items_by_topmost_item_name,\n",
    "    parse_metadata_by_object_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46ab8fed-b335-4d55-a73e-a6904bc0bc46",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kuzu dir: data/kg2c_lite_2.8.4.full.with-metanames.dataset.kuzu\n"
     ]
    }
   ],
   "source": [
    "# set data to be used throughout notebook\n",
    "chunk_size = 500000\n",
    "data_dir = \"data\"\n",
    "parquet_dir = f\"{data_dir}/\"\n",
    "source_data_url = \"https://github.com/ncats/translator-lfs-artifacts/raw/main/files/kg2c_lite_2.8.4.json.gz\"\n",
    "target_extracted_sample_data = (\n",
    "    f\"{data_dir}/{pathlib.Path(source_data_url).name.replace('.json.gz', '.json')}\"\n",
    ")\n",
    "parquet_dir = target_extracted_sample_data.replace(\".json\", \".full.dataset.parquet\")\n",
    "parquet_metanames_dir = target_extracted_sample_data.replace(\n",
    "    \".json\", \".full.with-metanames.dataset.parquet\"\n",
    ")\n",
    "kuzu_dir = target_extracted_sample_data.replace(\n",
    "    \".json\", \".full.with-metanames.dataset.kuzu\"\n",
    ")\n",
    "target_extracted_sample_data_schema_file = target_extracted_sample_data.replace(\n",
    "    \".json\", \".schema.json\"\n",
    ")\n",
    "print(f\"Kuzu dir: {kuzu_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dc7f93e-e2ea-4840-868b-885afaff38f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create path for the kuzu database to reside\n",
    "if pathlib.Path(kuzu_dir).is_dir():\n",
    "    shutil.rmtree(kuzu_dir)\n",
    "pathlib.Path(kuzu_dir).mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b65ae82e-cdb2-4c10-a5a5-4114c327a06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init a Kuzu database and connection\n",
    "db = kuzu.Database(f\"{kuzu_dir}\")\n",
    "kz_conn = kuzu.Connection(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "760b5a53-a85f-4334-ad39-dcd4807edabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_table_names_from_parquet_path(\n",
    "    parquet_path: str,\n",
    "    column_with_table_name: str = \"id\",\n",
    "):\n",
    "    with duckdb.connect() as ddb:\n",
    "        return [\n",
    "            element[0]\n",
    "            for element in ddb.execute(\n",
    "                f\"\"\"\n",
    "            SELECT DISTINCT {column_with_table_name}\n",
    "            FROM read_parquet('{parquet_path}')\n",
    "            \"\"\"\n",
    "            ).fetchall()\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5deec4e1-6b53-42fb-afc8-1e55a5ca5104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cypher_table_create_stmt_from_parquet_path(\n",
    "    parquet_path: str,\n",
    "    table_type: Literal[\"node\", \"rel\"],\n",
    "    table_name: str,\n",
    "    rel_table_field_mapping: Dict[str, str] = {\"from\": \"nodes\", \"to\": \"nodes\"},\n",
    "    table_pkey_parquet_field_name: str = \"id\",\n",
    "    edges_to_or_from_fieldnames: List[str] = [\"subject\", \"object\"],\n",
    "):\n",
    "\n",
    "    if pathlib.Path(parquet_path).is_dir():\n",
    "        # use first file discovered as basis for schema\n",
    "        parquet_path = next(pathlib.Path(parquet_path).glob(\"*.parquet\"))\n",
    "\n",
    "    parquet_schema = parquet.read_schema(parquet_path)\n",
    "\n",
    "    # Map Parquet data types to Cypher data types\n",
    "    # more details here: https://kuzudb.com/docusaurus/cypher/data-types/\n",
    "    parquet_to_cypher_type_mapping = {\n",
    "        \"string\": \"STRING\",\n",
    "        \"int32\": \"INT32\",\n",
    "        \"int64\": \"INT64\",\n",
    "        \"number\": \"FLOAT\",\n",
    "        \"float\": \"FLOAT\",\n",
    "        \"double\": \"FLOAT\",\n",
    "        \"boolean\": \"BOOLEAN\",\n",
    "        \"object\": \"MAP\",\n",
    "        \"array\": \"INT64[]\",\n",
    "        \"list<element: string>\": \"STRING[]\",\n",
    "        \"null\": \"NULL\",\n",
    "        \"date\": \"DATE\",\n",
    "        \"time\": \"TIME\",\n",
    "        \"datetime\": \"DATETIME\",\n",
    "        \"timestamp\": \"DATETIME\",\n",
    "        \"any\": \"ANY\",\n",
    "    }\n",
    "\n",
    "    # Generate Cypher field type statements\n",
    "    cypher_fields_from_parquet_schema = \", \".join(\n",
    "        [\n",
    "            # note: we use string splitting here for nested types\n",
    "            # for ex. list<element: string>\n",
    "            f\"{field.name} {parquet_to_cypher_type_mapping.get(str(field.type))}\"\n",
    "            for idx, field in enumerate(parquet_schema)\n",
    "            if table_type == \"node\" or (table_type == \"rel\" and idx > 1)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # branch for creating node table\n",
    "    if table_type == \"node\":\n",
    "\n",
    "        if table_pkey_parquet_field_name not in [\n",
    "            field.name for field in parquet_schema\n",
    "        ]:\n",
    "            raise LookupError(\n",
    "                f\"Unable to find field {table_pkey_parquet_field_name} in parquet file {parquet_path}.\"\n",
    "            )\n",
    "\n",
    "        return (\n",
    "            f\"CREATE NODE TABLE {table_name}\"\n",
    "            f\"({cypher_fields_from_parquet_schema}, \"\n",
    "            f\"PRIMARY KEY ({table_pkey_parquet_field_name}))\"\n",
    "        )\n",
    "\n",
    "    # else we return for rel tables\n",
    "    return (\n",
    "        f\"CREATE REL TABLE {table_name}\"\n",
    "        f\"(FROM {rel_table_field_mapping['from']} TO {rel_table_field_mapping['to']}, \"\n",
    "        f\"{cypher_fields_from_parquet_schema})\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09efe6c-0212-4da2-8712-e6be15461004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_node_category_from_id(nodes_dataset_path: str, node_id: str):\n",
    "    with duckdb.connect() as ddb:\n",
    "        return ddb.execute(\n",
    "            f\"\"\"\n",
    "            SELECT DISTINCT category\n",
    "            FROM read_parquet('{nodes_dataset_path}') node\n",
    "            WHERE node.id = '{node_id}';\n",
    "            \"\"\"\n",
    "        ).fetchone()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d57098-70d4-4db8-bedf-8b087bfd7784",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name_to_cypher_table_type_map = {\"nodes\": \"node\", \"edges\": \"rel\"}\n",
    "\n",
    "lookup_func = object()\n",
    "\n",
    "for path, table_name_column, primary_key in [\n",
    "    [f\"{parquet_metanames_dir}/nodes\", \"category\", \"id\"],\n",
    "    [f\"{parquet_metanames_dir}/edges\", \"predicate\", None],\n",
    "]:\n",
    "\n",
    "    decoded_type = dataset_name_to_cypher_table_type_map[pathlib.Path(path).name]\n",
    "    if decoded_type == \"nodes\":\n",
    "        lookup_func = partial(\n",
    "            lookup_node_category_from_id, nodes_dataset_path=f\"{path}/**\"\n",
    "        )\n",
    "\n",
    "    saver = \"\"\n",
    "\n",
    "    count = 0\n",
    "    for table_name in gather_table_names_from_parquet_path(\n",
    "        parquet_path=f\"{path}/**\", column_with_table_name=table_name_column\n",
    "    ):\n",
    "        # create metanames / objects using cypher safe name and dir\n",
    "        cypher_safe_table_name = table_name.split(\":\")[1]\n",
    "        parquet_metanames_metaname_base = f\"{path}/{cypher_safe_table_name}\"\n",
    "\n",
    "        drop_table_if_exists(kz_conn=kz_conn, table_name=cypher_safe_table_name)\n",
    "\n",
    "        print(parquet_metanames_metaname_base)\n",
    "\n",
    "        if decoded_type != \"rel\":\n",
    "            saver = cypher_safe_table_name\n",
    "\n",
    "        create_stmt = generate_cypher_table_create_stmt_from_parquet_path(\n",
    "            parquet_path=parquet_metanames_metaname_base,\n",
    "            table_type=decoded_type,\n",
    "            table_name=cypher_safe_table_name,\n",
    "            table_pkey_parquet_field_name=primary_key,\n",
    "            rel_table_field_mapping={\"from\": saver, \"to\": saver},\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"Using the following create statement to create table:\\n\\n{create_stmt}\\n\\n\"\n",
    "        )\n",
    "        kz_conn.execute(create_stmt)\n",
    "        count += 1\n",
    "        if count == 2:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0e913c0-d616-4177-995e-03e33541876c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               subj_category                        obj_category\n",
      "0      biolink:SmallMolecule        biolink:PhysiologicalProcess\n",
      "1               biolink:Gene  biolink:DiseaseOrPhenotypicFeature\n",
      "2  biolink:NucleicAcidEntity          biolink:GeneticInheritance\n",
      "3  biolink:PhenotypicFeature           biolink:PhenotypicFeature\n",
      "4      biolink:GenomicEntity                     biolink:Disease\n"
     ]
    }
   ],
   "source": [
    "with duckdb.connect() as ddb:\n",
    "    result = ddb.execute(\n",
    "        \"\"\"\n",
    "\n",
    "            SELECT DISTINCT \n",
    "                subj_node.category as subj_category,\n",
    "                obj_node.category as obj_category\n",
    "            FROM read_parquet('data/kg2c_lite_2.8.4.full.dataset.parquet/edges/*') edge\n",
    "            LEFT JOIN read_parquet('data/kg2c_lite_2.8.4.full.dataset.parquet/nodes/*') AS subj_node ON\n",
    "                edge.subject = subj_node.id\n",
    "            LEFT JOIN read_parquet('data/kg2c_lite_2.8.4.full.dataset.parquet/nodes/*') AS obj_node ON\n",
    "                edge.object = obj_node.id\n",
    "            WHERE edge.predicate='biolink:causes'\n",
    "            limit 5\n",
    "\n",
    "        \"\"\"\n",
    "    ).df()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a75ef8d-b58c-4937-a46e-fe22eb52af16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: we provide specific ordering here to ensure nodes are created before edges\n",
    "for path in [f\"{parquet_dir}/nodes\", f\"{parquet_dir}/edges\"]:\n",
    "\n",
    "    print(f\"Working on kuzu ingest of parquet dataset: {path} \")\n",
    "    # uses wildcard functionality for all files under parquet dataset dir\n",
    "    # see: https://kuzudb.com/docusaurus/data-import/csv-import#copy-from-multiple-csv-files-to-a-single-table\n",
    "    kz_conn.execute(f'COPY {pathlib.Path(path).name} FROM \"{path}/*.parquet\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
